# tests/test_api.py

import os
import sys
import tempfile
import pytest
from fastapi.testclient import TestClient
from unittest.mock import patch

# Add the project root to the Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from api.main import app, get_db
from database import Database

# Get the absolute path to the test PGN file
TESTS_DIR = os.path.dirname(os.path.abspath(__file__))
TEST_PGN_PATH = os.path.join(TESTS_DIR, '..', 'games', 'sample_game.pgn')

# --- Test Database Fixture and Dependency Override ---
@pytest.fixture
def client():
    """
    Pytest fixture that creates a TestClient with an overridden database dependency.
    It sets up a temporary database for the test, applies the override, yields
    the client, and then cleans up the database and override.
    """
    db_fd, db_path = tempfile.mkstemp(suffix=".db")
    os.close(db_fd)

    def _override_get_db():
        db = Database(db_path=db_path)
        try:
            db.connect()
            db.init_db()
            yield db
        finally:
            db.close()

    app.dependency_overrides[get_db] = _override_get_db

    yield TestClient(app)

    # Cleanup
    app.dependency_overrides.clear()
    os.remove(db_path)


@patch('coach.ollama.chat')
@patch('coach.Stockfish')
def test_analyze_pgn_file_api(mock_stockfish_class, mock_ollama_chat, client):
    """
    Tests the /analyze/ endpoint with a sample PGN file, using dependency override for the DB.
    The 'override_get_db' fixture handles the DB setup and teardown.
    """
    # 1. ARRANGE
    # Mock the LLM response
    mock_mistake_tag = "Hanging Piece"
    mock_explanation = "This is a mock explanation from the API test."
    mock_ollama_chat.return_value = {
        'message': {
            'content': f'{{"mistake_tag": "{mock_mistake_tag}", "explanation": "{mock_explanation}"}}'
        }
    }

    # Mock Stockfish to produce a blunder on a move from sample_game.pgn
    mock_stockfish_instance = mock_stockfish_class.return_value
    # FENs generated by get_fens.py for correctness
    fen_before_blunder = 'r1bq1rk1/pppp1ppp/2n5/2b1P3/2Bp1Bn1/5N1P/PPP2PP1/RN1Q1RK1 b - - 0 8'
    fen_after_blunder = 'r1bq1rk1/pppp1ppp/2n5/2b1n3/2Bp1B2/5N1P/PPP2PP1/RN1Q1RK1 w - - 0 9'
    current_fen = ""
    blunder_has_occurred = False

    def set_fen_side_effect(fen):
        nonlocal current_fen
        current_fen = fen
    mock_stockfish_instance.set_fen_position.side_effect = set_fen_side_effect

    def get_evaluation_side_effect():
        nonlocal blunder_has_occurred
        # Once the blunder occurs, keep the evaluation high to prevent a second, phantom blunder.
        if blunder_has_occurred:
            return {'type': 'cp', 'value': 600}
        
        if current_fen == fen_before_blunder:
            return {'type': 'cp', 'value': 50}  # Score before blunder
        
        if current_fen == fen_after_blunder:
            blunder_has_occurred = True
            return {'type': 'cp', 'value': 600} # Score after blunder

        return {'type': 'cp', 'value': 0}

    mock_stockfish_instance.get_evaluation.side_effect = get_evaluation_side_effect
    # Set a realistic best move (in UCI format) for the position before the blunder
    mock_stockfish_instance.get_best_move.return_value = 'd7d5'

    # 2. ACT
    with open(TEST_PGN_PATH, 'rb') as pgn_file:
        response = client.post(
            "/analyze/",
            files={"pgn_file": ("sample_game.pgn", pgn_file, "application/vnd.chess-pgn")}
        )

    # 3. ASSERT
    assert response.status_code == 200, f"API call failed with {response.status_code}: {response.text}"

    response_data = response.json()
    assert "analysis" in response_data
    analysis_results = response_data["analysis"]
    assert len(analysis_results) == 1, "API did not return the expected number of blunders."

    blunder = analysis_results[0]
    assert blunder['move_san'] == "Ngxe5"
    assert blunder['player_color'] == "Black"
    assert blunder['mistake_tag'] == mock_mistake_tag
    assert blunder['coach_comment'] == mock_explanation
    assert blunder['eval_drop'] == 550  # 600 - 50 = 550
